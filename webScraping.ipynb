from bs4 import BeautifulSoup as bs
from pprint import pprint
from urllib.request import urlopen
import requests
# from selenium import webdriver
# from selenium.webdriver.common.by import By
# from selenium.webdriver.common.keys import Keys
from datetime import datetime

# 오늘 날짜
dateToday = datetime.today().strftime("%Y.%m.%d.")

# 헤더 : User-Agent 설정
headers = {'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}

# html = requests.get("https://store.kyobobook.co.kr/bestseller/online/daily")
# pprint(html.text)
url = 'https://datalab.naver.com/'
html = requests.get(url, headers = headers)
soup = bs(html.content, 'html.parser')

data1 = soup.findAll('span', class_='title_cell')
target_div = soup.select('div.keyword_rank span')
# span 태그의 title_cell 클래스의 내용과 '오늘' 날짜값이 일치하면 해당 내용을 출력하게 하고 싶은데.
print(data1)
pprint(target_div)

# 웹 페이지는 HTML이라는 언어로 쓰여져있습니다. 이를 파이썬에서 쉽게 분석할 수 있도록 파싱작업을 거쳐 각 요소에 접근이 쉽게 만듭니다.


# 그러려 먼 간단한 설정을 해주어야 하는데... 이유는 네이버에서 크롤링을 막았다고 해야 하나...? 
# 아무튼 위의 방법대로 접근을 해보면 빈 배열만 나오고 크롤링이 안됨 -> 네이버, 교보문고 등 큰 웹사이트들은 크롤링을 막은듯

# soup = bs(html.text, 'html.parser')

# data1 = soup.findAll('div', {'class':'ml-4 min-w-[516px] w-full'})
# pprint(data1)

# data2 = data1.find('strong')
# pprint(data2)
