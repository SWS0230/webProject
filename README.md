# webProject

책을 추천해주는 사이트를 만들겁니다. 가장 기본적으로는 1.추천받고 싶은 분야 입력 2.교보문고, 알라딘, Yes24 등 각종 도서 사이트에서 해당 분야 베스트셀러 10권을 추출 3. 추출한 책들을 다시 출력. 간단하죠?

# 25.01.20 Update Log
1. 네이버 데이터랩의 도서 일간 상위 검색어 긁어오는게 좀 빡세서(아마 웹사이트 구조 자체를 잘 이해 못한 것 같긴 함) 그냥 기존에 하려고 한 교보문고 일간 베스트셀러 긁어오기 진행하려고 함
2. bs4 쓰려고 했는데 자꾸 빈배열 불러오길래 셀레늄 쓰기로 함, 그런데도 알 수 없는 오류가 뜸. 내일 오류에 대해서 더 알아보기로 함
3. Replit에서 Webdriver 쓰는 법 터득함 : ipynb의 Selenium & Webdriver 관련 코드 복붙하면 됨

# 25.01.21 Update Log
1. 교보문고의 태그 및 클래스명이 너무 난해한 탓인지 자꾸 빈배열을 쳐@반환하길래 때려쳤다.
2. 모 블로그에서 내가 하려고 한 짓을 똑같이 했다. 알라딘의 베스트셀러 크롤러를 만들어놨길래 그대로 보면서 클래스명이 단순한 서점 사이트들 위주로 크롤러를 만들어놔야겠다. 교보같이 크고 복잡한 거는 나중에..

# 25.01.22 Update Log
1. 우연히 내가 하려는 거랑 똑같은 웹 크롤러를 만든 사람이 있어서 참고(복붙)함 -> 알라딘, yes24는 잘 된다. 영풍문고, 교보문고는 안된다. 진짜 이유가 너무 궁금함
2. 그래서 코드를 그냥 갈아엎고 일단 aladin, yes24의 주간 베스트셀러를 긁어다가 pandas를 사용해 csv 파일로 정리하는 것까지 해놨다.
3. 앞으로 할 것 : 해당 csv 파일을 이 주피터 노트북에서 빼다가(추출해서) 내가 작업중인 js파일에 연동시킬 수 있어야 함.
(여차하면 그냥 HTML 기존 작업하던 repl에 py 파일을 만들까 싶기도 하고..)

# 25.01.23 Thinking Log
1. 불침번 때문에 오늘은 업뎃을 못함.
2. 파이썬에서 만든 csv 파일을 SQL 데이터베이스로 보내서, 기존 웹페이지가 그 데이터베이스를 참조하도록 만드는 것도 방법이 될 것 같다.
3. 살짝 돌아가는 감은 있지만, '아무튼 구현해보자'가 답이니까 이렇게 하는 것 역시 방법이 될 것임

# 25.01.26 Update Log
1. 파이썬의 플라스크를 배우기 시작함.
왜? 파이썬에서 웹 스크래핑하여 긁어온 뒤 만들어낸 csv 파일을 데이터베이스로 처리하여 다시 프론트엔드로 보내기 위해서는, 파이썬의 웹 프레임워크를 사용해야 될 것 같았음.
2. chatGPT를 사용해 bs4로 웹에서 스크래핑하여 pandas로 추출한 csv 파일을 flask 웹 서버로 읽어 이를 index.html로 출력할 수 있게 됨. 짝짝짝 근데 로컬환경이 아니라는 게 진짜 빡세긴 하다고 느낌
3. 기존의 5권까지는 성공적으로 진행됐는데, 어떠한 이유에서인지 10권 출력이 안됨. 아마 각 셀의 길이가 서로 달라서 그런 것 같은데, 다음에 해결해보기로 하자.


